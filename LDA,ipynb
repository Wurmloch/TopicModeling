{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation LDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikifetcher\n",
    "Raw Text von Wikipedia mittels Suchbegriffen\n",
    "#### LDAbuilder\n",
    "Ausführen der LDA mit der gegebenen Dokumentliste (Rohtext-Liste von Wikifetcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausführung\n",
    "### Konfiguration \n",
    "- Wir benötigen Zugriff auf Wikipedia für den Rohtext\n",
    "- Natural Language Toolkit NLTK für die Tokenisierung und Stemming\n",
    "- Stop_words, um nichtssagende Wörter zu entfernen\n",
    "- Gensim für die Implementierung der Latent Dirichlet Allocation LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "from gensim import corpora, models\n",
    "\n",
    "sentence_pat = re.compile(r'([A-Z][^\\.!?]*[\\.!?])', re.M)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Erzeuge englische stop words Liste\n",
    "en_stop = get_stop_words('en')\n",
    "# Erzeuge p_stemmer der Klasse PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "doc_list = []\n",
    "wikipedia.set_lang('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia Content\n",
    "Mittels Suchbegriffen holen wir den Rohen Inhalt aus Wikipedia.\n",
    "Danach wird der Inhalt in Sätze getrennt, welche zur Dokumentliste hinzugefügt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stuttgart ( SHTUUT-gart; German: [ˈʃtʊtɡaʁt] ( listen); Swabian: Schduagert, pronounced [ˈʒ̊d̥ua̯ɡ̊ɛʕd̥]; names in other languages) is the capital and largest city of the German state of Baden-Württemberg.\n",
      "Stuttgart is located on the Neckar river in a fertile valley locally known as the \"Stuttgart Cauldron\" an hour from the Swabian Jura and the Black Forest, and its urban area has a population of 609,219, making it the sixth largest city in Germany. 2.7 million people live in the city's administrative region and another 5.3 million people in its metropolitan area, making it the fourth largest metropolitan area in Germany.\n",
      "The city and metropolitan area are consistently ranked among the top 20 European metropolitan areas by GDP; Mercer listed Stuttgart as 21st on its 2015 list of cities by quality of living, innovation agency 2thinknow ranked the city 24th globally out of 442 cities  and the Globalization and World Cities Research Network ranked the city as a Beta-status world city in their 2014 survey.\n",
      "Since the 6th millennium BC, the Stuttgart area has been an important agricultural area and has been host to a number of cultures seeking to utilize the rich soil of the Neckar valley. The Roman Empire conquered the area in 83 AD and built a massive castrum near Bad Cannstatt, making it the most important regional center for several centuries. Stuttgart's roots were truly laid in the 10th century with its founding by Liudolf, Duke of Swabia, as a stud farm for his warhorses. Ov...\n"
     ]
    }
   ],
   "source": [
    "def get_page(name):\n",
    "    first_found = wikipedia.search(name)[0]\n",
    "    try:\n",
    "        return(wikipedia.page(first_found).content)\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return(wikipedia.page(e.options[0]).content)\n",
    "    \n",
    "search_terms = ['Stuttgart']\n",
    "separator = '== References =='\n",
    "for term in search_terms:\n",
    "    full_content = get_page(term).split(separator, 1)[0]\n",
    "    sentence_list = sentence_pat.findall(full_content)\n",
    "    for sentence in sentence_list:\n",
    "        doc_list.append(sentence)\n",
    "\n",
    "    print(full_content[0:1500] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorverarbeitung\n",
    "Der Text wird nun Tokenisiert, gestemt, nutzlose Wörter werden entfernt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_topics = 4\n",
    "num_words_per_topic = 15\n",
    "texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [stuttgart, shtuut, gart, german, ˈʃtʊtɡaʁt, l...\n",
      "1      [stuttgart, locat, neckar, river, fertil, vall...\n",
      "2                                              [germani]\n",
      "3      [citi, metropolitan, area, consist, rank, amon...\n",
      "4      [sinc, 6th, millennium, bc, stuttgart, area, i...\n",
      "5      [roman, empir, conquer, area, 83, ad, built, m...\n",
      "6      [stuttgart, s, root, truli, laid, 10th, centur...\n",
      "7      [overshadow, nearbi, cannstatt, town, grew, st...\n",
      "8      [fortun, stuttgart, turn, hous, württemberg, m...\n",
      "9      [stuttgart, prosper, despit, setback, thirti, ...\n",
      "10     [howev, 1952, citi, bounc, back, becam, major,...\n",
      "11     [stuttgart, also, transport, junction, possess...\n",
      "12              [stuttgart, unusu, scheme, german, citi]\n",
      "13     [spread, across, varieti, hill, cover, vineyar...\n",
      "14     [often, sourc, surpris, visitor, associ, citi,...\n",
      "15          [citi, s, tourism, slogan, stuttgart, offer]\n",
      "16     [current, plan, improv, transport, link, inter...\n",
      "17                    [busi, describ, busi, meet, futur]\n",
      "18     [juli, 2010, stuttgart, unveil, new, citi, log...\n",
      "19               [stuttgart, citi, high, number, immigr]\n",
      "20     [accord, dorl, kindersley, s, eyewit, travel, ...\n",
      "21     [stuttgart, s, resid, 64, popul, age, five, im...\n",
      "22     [name, stuttgart, often, nicknam, schwabenmetr...\n",
      "23     [histori, antiqu, origin, import, locat, necka...\n",
      "24     [thu, first, settlement, stuttgart, massiv, ro...\n",
      "25     [ad, protect, villa, vineyard, blanket, landsc...\n",
      "26     [mani, militari, instal, settlement, sprang, n...\n",
      "27     [town, left, capabl, hand, local, brickwork, p...\n",
      "28     [roman, driven, back, past, rhine, danub, rive...\n",
      "29     [middl, age, 700, duke, gotfrid, mention, chan...\n",
      "                             ...                        \n",
      "494    [current, play, regionalliga, südwest, fourth,...\n",
      "495    [lower, divis, footbal, team, sportfreund, stu...\n",
      "496    [sport, stuttgart, home, vfl, pfullingen, stut...\n",
      "497    [three, time, german, champion, women, s, voll...\n",
      "498           [stuttgart, two, major, ice, hockey, team]\n",
      "499    [stuttgart, rebel, ec, play, landesliga, 4th, ...\n",
      "500    [bietigheim, bissingen, steeler, play, 2nd, di...\n",
      "501    [steeler, play, new, ege, tran, arena, bietigh...\n",
      "502    [strongest, local, water, polo, team, sv, cann...\n",
      "503    [stuttgart, two, american, footbal, team, stut...\n",
      "504    [australian, footbal, practic, stuttgart, emu,...\n",
      "505    [particip, australian, footbal, leagu, germani...\n",
      "506    [anoth, women, s, team, tec, waldau, stuttgart...\n",
      "507    [htc, stuttgart, kicker, one, success, field, ...\n",
      "508    [sport, event, stuttgart, reput, stage, major,...\n",
      "509    [also, one, twelv, host, citi, fifa, world, cu...\n",
      "510    [six, match, three, second, round, match, incl...\n",
      "511    [stuttgart, also, 2007, european, capit, sport...\n",
      "512    [famou, sport, venu, weissenhof, tenni, court,...\n",
      "513                               [scharrena, stuttgart]\n",
      "514    [intern, relat, twin, town, sister, citi, stut...\n",
      "515    [notabl, resid, popular, cultur, game, 2003, v...\n",
      "516    [first, chines, mission, player, must, reclaim...\n",
      "517    [medic, valv, s, 2007, first, person, shooter,...\n",
      "518    [2008, episod, adventur, game, sam, max, beyon...\n",
      "519    [reinhardt, one, tank, class, blizzard, s, 201...\n",
      "520    [furthermor, game, also, featur, map, eichenwa...\n",
      "521    [novel, 2005, novel, book, thief, protagonist,...\n",
      "522    [tv, cinema, 2012, film, aveng, villain, loki,...\n",
      "523    [scene, actual, film, cleveland, ohio, number,...\n",
      "Length: 524, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for doc in doc_list:\n",
    "    raw = doc.lower()\n",
    "    # Erzeuge tokens\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    # Entferne unnütze Information\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    # Stemme tokens - Entfernung von Duplikaten und Transformation zu Grundform\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    texts.append(stemmed_tokens)\n",
    "output_preprocessed = pd.Series(texts)\n",
    "print(output_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary und Vektoren\n",
    "In diesem Abschnitt wird nun der Bag-of-words Korpus erstellt. Die Vektoren werden später für das LDA-Modell benötigt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1...\n",
      "1      [(0, 2), (6, 1), (17, 1), (18, 1), (22, 1), (2...\n",
      "2                                              [(41, 1)]\n",
      "3      [(0, 1), (18, 7), (35, 2), (42, 2), (43, 1), (...\n",
      "4      [(0, 1), (23, 1), (26, 1), (35, 2), (69, 1), (...\n",
      "5      [(35, 1), (39, 1), (73, 1), (82, 1), (83, 1), ...\n",
      "6      [(0, 1), (96, 1), (97, 1), (98, 1), (99, 1), (...\n",
      "7      [(92, 1), (109, 1), (110, 1), (111, 1), (112, ...\n",
      "8      [(0, 1), (16, 1), (21, 1), (96, 1), (117, 1), ...\n",
      "9      [(0, 1), (18, 1), (126, 1), (127, 1), (128, 1)...\n",
      "10     [(18, 1), (94, 1), (138, 1), (139, 1), (140, 1...\n",
      "11     [(0, 1), (17, 1), (40, 1), (41, 1), (149, 1), ...\n",
      "12         [(0, 1), (3, 1), (18, 1), (164, 1), (165, 1)]\n",
      "13     [(0, 1), (23, 1), (24, 1), (26, 1), (166, 1), ...\n",
      "14     [(18, 1), (136, 1), (176, 1), (177, 1), (178, ...\n",
      "15     [(0, 1), (18, 1), (97, 1), (146, 1), (183, 1),...\n",
      "16     [(0, 1), (18, 1), (150, 1), (183, 1), (185, 1)...\n",
      "17              [(199, 1), (206, 2), (207, 1), (208, 1)]\n",
      "18     [(0, 1), (18, 2), (35, 1), (194, 1), (195, 1),...\n",
      "19        [(0, 1), (18, 1), (76, 1), (217, 1), (218, 1)]\n",
      "20     [(0, 1), (18, 1), (41, 1), (97, 1), (219, 1), ...\n",
      "21     [(0, 1), (36, 1), (97, 1), (218, 1), (229, 1),...\n",
      "22     [(0, 1), (3, 1), (6, 2), (14, 1), (18, 1), (22...\n",
      "23     [(0, 1), (22, 1), (23, 1), (24, 1), (26, 1), (...\n",
      "24     [(0, 1), (82, 1), (87, 1), (88, 1), (89, 1), (...\n",
      "25     [(86, 1), (171, 1), (259, 1), (260, 1), (261, ...\n",
      "26     [(110, 1), (255, 1), (269, 1), (270, 1), (271,...\n",
      "27     [(27, 1), (111, 1), (278, 1), (279, 1), (280, ...\n",
      "28     [(24, 1), (82, 1), (96, 2), (141, 1), (248, 1)...\n",
      "29     [(104, 1), (231, 1), (296, 1), (297, 1), (298,...\n",
      "                             ...                        \n",
      "494    [(185, 1), (880, 1), (884, 1), (1521, 1), (176...\n",
      "495    [(0, 1), (62, 1), (191, 1), (254, 1), (462, 1)...\n",
      "496    [(0, 2), (27, 1), (505, 1), (573, 1), (880, 1)...\n",
      "497    [(0, 1), (3, 1), (97, 2), (380, 1), (573, 1), ...\n",
      "498    [(0, 1), (143, 1), (651, 1), (1059, 1), (2518,...\n",
      "499    [(0, 1), (880, 1), (2437, 1), (2518, 1), (2520...\n",
      "500    [(880, 1), (884, 1), (1195, 1), (2527, 1), (25...\n",
      "501    [(195, 1), (880, 1), (1426, 1), (2527, 1), (25...\n",
      "502    [(3, 1), (27, 1), (92, 1), (676, 1), (1059, 1)...\n",
      "503    [(0, 4), (205, 1), (573, 1), (651, 1), (714, 1...\n",
      "504    [(0, 1), (41, 1), (509, 1), (1045, 1), (1059, ...\n",
      "505    [(0, 1), (3, 1), (41, 1), (97, 1), (370, 1), (...\n",
      "506    [(0, 1), (3, 1), (97, 1), (716, 1), (1059, 1),...\n",
      "507    [(0, 1), (3, 1), (41, 1), (48, 1), (366, 1), (...\n",
      "508    [(0, 1), (62, 2), (143, 1), (181, 1), (558, 1)...\n",
      "509    [(18, 1), (62, 1), (75, 1), (149, 1), (509, 1)...\n",
      "510    [(148, 1), (157, 1), (158, 1), (159, 1), (291,...\n",
      "511    [(0, 1), (16, 1), (48, 1), (62, 2), (75, 1), (...\n",
      "512    [(75, 1), (155, 1), (157, 1), (307, 1), (596, ...\n",
      "513                                  [(0, 1), (2567, 1)]\n",
      "514    [(0, 2), (17, 2), (18, 4), (91, 1), (92, 1), (...\n",
      "515    [(0, 1), (30, 1), (77, 1), (84, 1), (229, 1), ...\n",
      "516    [(18, 1), (254, 1), (1433, 1), (1856, 1), (257...\n",
      "517    [(0, 1), (23, 1), (97, 1), (241, 1), (254, 1),...\n",
      "518    [(0, 1), (198, 1), (223, 1), (366, 1), (380, 2...\n",
      "519    [(0, 1), (97, 1), (250, 1), (509, 1), (1042, 1...\n",
      "520    [(18, 1), (90, 1), (111, 1), (149, 1), (376, 1...\n",
      "521    [(0, 1), (229, 1), (308, 1), (1394, 1), (1853,...\n",
      "522    [(0, 1), (165, 1), (382, 1), (1456, 1), (1775,...\n",
      "523    [(0, 1), (18, 1), (76, 1), (97, 1), (229, 1), ...\n",
      "Length: 524, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Erzeuge ein dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "# Konvertiere dictionary in Bag-of-Words\n",
    "# corpus ist eine Liste von Vektoren - Jeder Dokument-Vektor ist eine Serie von Tupeln\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "output_vectors = pd.Series(corpus)\n",
    "print(output_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA-Modell\n",
    "Schließlich kann das LDA-Modell angewandt werden. Die Übergabeparameter dafür sind die Liste der Vektoren, die Anzahl der Themen, das Dictionary, sowie die Aktualisierungsrate.\n",
    "In der Trainingsphase sollte eine höhere Aktualisierungsrate >= 20 gewählt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.030*\"stuttgart\" + 0.025*\"citi\" + 0.008*\"württemberg\" + 0.007*\"s\" + 0.007*\"district\" + 0.005*\"also\" + 0.005*\"state\" + 0.005*\"area\" + 0.004*\"archiv\" + 0.004*\"librari\" + 0.004*\"german\" + 0.004*\"year\" + 0.004*\"new\" + 0.004*\"today\" + 0.003*\"intern\"\n",
      "1\n",
      "0.025*\"stuttgart\" + 0.011*\"s\" + 0.010*\"citi\" + 0.005*\"germani\" + 0.005*\"german\" + 0.004*\"last\" + 0.004*\"state\" + 0.004*\"000\" + 0.004*\"one\" + 0.004*\"centuri\" + 0.003*\"war\" + 0.003*\"later\" + 0.003*\"also\" + 0.003*\"home\" + 0.003*\"duke\"\n",
      "2\n",
      "0.036*\"stuttgart\" + 0.012*\"citi\" + 0.012*\"württemberg\" + 0.007*\"s\" + 0.006*\"world\" + 0.006*\"univers\" + 0.006*\"baden\" + 0.005*\"german\" + 0.005*\"germani\" + 0.005*\"also\" + 0.005*\"area\" + 0.004*\"state\" + 0.004*\"cannstatt\" + 0.004*\"center\" + 0.004*\"found\"\n",
      "3\n",
      "0.025*\"stuttgart\" + 0.013*\"citi\" + 0.009*\"s\" + 0.007*\"us\" + 0.006*\"germani\" + 0.006*\"area\" + 0.005*\"local\" + 0.005*\"sinc\" + 0.005*\"museum\" + 0.005*\"armi\" + 0.005*\"year\" + 0.005*\"war\" + 0.004*\"württemberg\" + 0.004*\"german\" + 0.004*\"town\"\n"
     ]
    }
   ],
   "source": [
    "# Wende LDA-Modell an\n",
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=num_topics, id2word = dictionary, passes=20)\n",
    "lda = ldamodel.print_topics(num_topics=num_topics, num_words=num_words_per_topic)\n",
    "    \n",
    "for topic in lda:\n",
    "    for entry in topic:\n",
    "        print(entry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
